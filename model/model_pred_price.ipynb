{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/merge_all/merge_all.csv\", index_col=0)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03', '2000-01-04',\n",
       "               '2000-01-05', '2000-01-06', '2000-01-07', '2000-01-08',\n",
       "               '2000-01-09', '2000-01-10',\n",
       "               ...\n",
       "               '2022-11-21', '2022-11-22', '2022-11-23', '2022-11-24',\n",
       "               '2022-11-25', '2022-11-26', '2022-11-27', '2022-11-28',\n",
       "               '2022-11-29', '2022-11-30'],\n",
       "              dtype='datetime64[ns]', name='거래년월일', length=8370, freq=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스를 datetime으로 변경\n",
    "df.index = pd.to_datetime(df.index,format=\"%Y-%m-%d\")\n",
    "# df.index\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling 메소드를 이용한 이동평균 만들기\n",
    "mov_list = [7,28]\n",
    "for mov in mov_list :\n",
    "    globals()[\"df_mov_avr\"+str(mov)] = df[\"평균\"].rolling(mov, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "거래년월일\n",
       "2000-01-01    5600.0\n",
       "2000-01-02    5600.0\n",
       "2000-01-03    5600.0\n",
       "2000-01-04    5600.0\n",
       "2000-01-05    5600.0\n",
       "               ...  \n",
       "2022-11-26    6100.0\n",
       "2022-11-27    6100.0\n",
       "2022-11-28    6100.0\n",
       "2022-11-29    5664.0\n",
       "2022-11-30    5592.0\n",
       "Name: 평균, Length: 8370, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yester = df[\"평균\"].shift(1)      # 전날 가격을 추출\n",
    "df_yester[0] = (6040+5160)/2        # 1999년 12월 31일 배추 평균값\n",
    "# df_yester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>자동차용 경유 가격 (원)</th>\n",
       "      <th>전월비(%)</th>\n",
       "      <th>평균</th>\n",
       "      <th>거래량</th>\n",
       "      <th>평균</th>\n",
       "      <th>평균</th>\n",
       "      <th>평균</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>거래년월일</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>583.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>102285.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>5600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>583.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>102285.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>5600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>583.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>102285.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>5600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>583.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>715338.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5600.000000</td>\n",
       "      <td>5600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>583.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5620.0</td>\n",
       "      <td>340568.0</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>5604.000000</td>\n",
       "      <td>5604.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-26</th>\n",
       "      <td>1879.15</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>296250.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>6282.571429</td>\n",
       "      <td>6898.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>1879.15</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>296250.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>6151.428571</td>\n",
       "      <td>6833.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-28</th>\n",
       "      <td>1879.15</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5664.0</td>\n",
       "      <td>201478.0</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>6060.571429</td>\n",
       "      <td>6757.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-29</th>\n",
       "      <td>1879.15</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5592.0</td>\n",
       "      <td>77130.0</td>\n",
       "      <td>5664.0</td>\n",
       "      <td>5965.142857</td>\n",
       "      <td>6694.410714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-30</th>\n",
       "      <td>1879.15</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5242.0</td>\n",
       "      <td>119783.0</td>\n",
       "      <td>5592.0</td>\n",
       "      <td>5842.571429</td>\n",
       "      <td>6637.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8370 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            자동차용 경유 가격 (원)  전월비(%)      평균       거래량      평균           평균  \\\n",
       "거래년월일                                                                       \n",
       "2000-01-01          583.35     4.0  5600.0  102285.0  5600.0  5600.000000   \n",
       "2000-01-02          583.35     4.0  5600.0  102285.0  5600.0  5600.000000   \n",
       "2000-01-03          583.35     4.0  5600.0  102285.0  5600.0  5600.000000   \n",
       "2000-01-04          583.35     4.0  5600.0  715338.0  5600.0  5600.000000   \n",
       "2000-01-05          583.35     4.0  5620.0  340568.0  5600.0  5604.000000   \n",
       "...                    ...     ...     ...       ...     ...          ...   \n",
       "2022-11-26         1879.15    -8.0  6100.0  296250.0  6100.0  6282.571429   \n",
       "2022-11-27         1879.15    -8.0  6100.0  296250.0  6100.0  6151.428571   \n",
       "2022-11-28         1879.15    -8.0  5664.0  201478.0  6100.0  6060.571429   \n",
       "2022-11-29         1879.15    -8.0  5592.0   77130.0  5664.0  5965.142857   \n",
       "2022-11-30         1879.15    -8.0  5242.0  119783.0  5592.0  5842.571429   \n",
       "\n",
       "                     평균  \n",
       "거래년월일                    \n",
       "2000-01-01  5600.000000  \n",
       "2000-01-02  5600.000000  \n",
       "2000-01-03  5600.000000  \n",
       "2000-01-04  5600.000000  \n",
       "2000-01-05  5604.000000  \n",
       "...                 ...  \n",
       "2022-11-26  6898.071429  \n",
       "2022-11-27  6833.214286  \n",
       "2022-11-28  6757.196429  \n",
       "2022-11-29  6694.410714  \n",
       "2022-11-30  6637.500000  \n",
       "\n",
       "[8370 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df_yester ,df_mov_avr7, df_mov_avr28],axis=1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8370 entries, 2000-01-01 to 2022-11-30\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   자동차용 경유 가격 (원)  8370 non-null   float64\n",
      " 1   전월비(%)          8370 non-null   float64\n",
      " 2   평균 가격(원)        8370 non-null   float64\n",
      " 3   거래량 (kg)        8370 non-null   float64\n",
      " 4   전일 평균가격         8370 non-null   float64\n",
      " 5   이동 평균가격_7일      8370 non-null   float64\n",
      " 6   이동 평균가격_28일     8370 non-null   float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 523.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.columns = [\"자동차용 경유 가격 (원)\", \"전월비(%)\", \"평균 가격(원)\", \"거래량 (kg)\", \"전일 평균가격\" ,\"이동 평균가격_7일\",\"이동 평균가격_28일\"]\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = df[[\"자동차용 경유 가격 (원)\", \"전월비(%)\", \"거래량 (kg)\", \"전일 평균가격\" ,\"이동 평균가격_7일\",\"이동 평균가격_28일\"]]\n",
    "target = df[\"평균 가격(원)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(feature)\n",
    "feature_std = std.transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "std2 = StandardScaler()\n",
    "std2.fit(target.values.reshape(-1,1))\n",
    "target_std = std2.transform(target.values.reshape(-1,1))\n",
    "# target_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8370, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝용 tensor로 변환\n",
    "X_train, X_test = feature_std[:6696].reshape(-1,3,1.), feature_std[6696:].reshape(-1,3,1)\n",
    "y_train, y_test = target_std[:6696], target_std[6696:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=3, input_shape=(X_train.shape[1],1), activation=\"tanh\", ))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mean_squared_error\",optimizer = \"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "210/210 - 4s - loss: 0.6320 - mse: 0.6320 - 4s/epoch - 19ms/step\n",
      "Epoch 2/300\n",
      "210/210 - 1s - loss: 0.5932 - mse: 0.5932 - 533ms/epoch - 3ms/step\n",
      "Epoch 3/300\n",
      "210/210 - 1s - loss: 0.5767 - mse: 0.5767 - 541ms/epoch - 3ms/step\n",
      "Epoch 4/300\n",
      "210/210 - 1s - loss: 0.5688 - mse: 0.5688 - 514ms/epoch - 2ms/step\n",
      "Epoch 5/300\n",
      "210/210 - 1s - loss: 0.5641 - mse: 0.5641 - 515ms/epoch - 2ms/step\n",
      "Epoch 6/300\n",
      "210/210 - 1s - loss: 0.5604 - mse: 0.5604 - 506ms/epoch - 2ms/step\n",
      "Epoch 7/300\n",
      "210/210 - 1s - loss: 0.5571 - mse: 0.5571 - 508ms/epoch - 2ms/step\n",
      "Epoch 8/300\n",
      "210/210 - 1s - loss: 0.5542 - mse: 0.5542 - 513ms/epoch - 2ms/step\n",
      "Epoch 9/300\n",
      "210/210 - 1s - loss: 0.5520 - mse: 0.5520 - 539ms/epoch - 3ms/step\n",
      "Epoch 10/300\n",
      "210/210 - 1s - loss: 0.5497 - mse: 0.5497 - 514ms/epoch - 2ms/step\n",
      "Epoch 11/300\n",
      "210/210 - 1s - loss: 0.5484 - mse: 0.5484 - 509ms/epoch - 2ms/step\n",
      "Epoch 12/300\n",
      "210/210 - 1s - loss: 0.5467 - mse: 0.5467 - 514ms/epoch - 2ms/step\n",
      "Epoch 13/300\n",
      "210/210 - 1s - loss: 0.5450 - mse: 0.5450 - 515ms/epoch - 2ms/step\n",
      "Epoch 14/300\n",
      "210/210 - 1s - loss: 0.5445 - mse: 0.5445 - 511ms/epoch - 2ms/step\n",
      "Epoch 15/300\n",
      "210/210 - 1s - loss: 0.5428 - mse: 0.5428 - 594ms/epoch - 3ms/step\n",
      "Epoch 16/300\n",
      "210/210 - 1s - loss: 0.5424 - mse: 0.5424 - 585ms/epoch - 3ms/step\n",
      "Epoch 17/300\n",
      "210/210 - 1s - loss: 0.5410 - mse: 0.5410 - 543ms/epoch - 3ms/step\n",
      "Epoch 18/300\n",
      "210/210 - 1s - loss: 0.5401 - mse: 0.5401 - 503ms/epoch - 2ms/step\n",
      "Epoch 19/300\n",
      "210/210 - 1s - loss: 0.5389 - mse: 0.5389 - 502ms/epoch - 2ms/step\n",
      "Epoch 20/300\n",
      "210/210 - 1s - loss: 0.5383 - mse: 0.5383 - 509ms/epoch - 2ms/step\n",
      "Epoch 21/300\n",
      "210/210 - 1s - loss: 0.5374 - mse: 0.5374 - 513ms/epoch - 2ms/step\n",
      "Epoch 22/300\n",
      "210/210 - 0s - loss: 0.5363 - mse: 0.5363 - 487ms/epoch - 2ms/step\n",
      "Epoch 23/300\n",
      "210/210 - 0s - loss: 0.5356 - mse: 0.5356 - 496ms/epoch - 2ms/step\n",
      "Epoch 24/300\n",
      "210/210 - 1s - loss: 0.5345 - mse: 0.5345 - 501ms/epoch - 2ms/step\n",
      "Epoch 25/300\n",
      "210/210 - 0s - loss: 0.5333 - mse: 0.5333 - 494ms/epoch - 2ms/step\n",
      "Epoch 26/300\n",
      "210/210 - 1s - loss: 0.5324 - mse: 0.5324 - 503ms/epoch - 2ms/step\n",
      "Epoch 27/300\n",
      "210/210 - 1s - loss: 0.5313 - mse: 0.5313 - 519ms/epoch - 2ms/step\n",
      "Epoch 28/300\n",
      "210/210 - 0s - loss: 0.5307 - mse: 0.5307 - 495ms/epoch - 2ms/step\n",
      "Epoch 29/300\n",
      "210/210 - 1s - loss: 0.5295 - mse: 0.5295 - 501ms/epoch - 2ms/step\n",
      "Epoch 30/300\n",
      "210/210 - 0s - loss: 0.5286 - mse: 0.5286 - 484ms/epoch - 2ms/step\n",
      "Epoch 31/300\n",
      "210/210 - 0s - loss: 0.5275 - mse: 0.5275 - 482ms/epoch - 2ms/step\n",
      "Epoch 32/300\n",
      "210/210 - 0s - loss: 0.5267 - mse: 0.5267 - 495ms/epoch - 2ms/step\n",
      "Epoch 33/300\n",
      "210/210 - 1s - loss: 0.5259 - mse: 0.5259 - 512ms/epoch - 2ms/step\n",
      "Epoch 34/300\n",
      "210/210 - 0s - loss: 0.5247 - mse: 0.5247 - 498ms/epoch - 2ms/step\n",
      "Epoch 35/300\n",
      "210/210 - 0s - loss: 0.5241 - mse: 0.5241 - 490ms/epoch - 2ms/step\n",
      "Epoch 36/300\n",
      "210/210 - 0s - loss: 0.5230 - mse: 0.5230 - 488ms/epoch - 2ms/step\n",
      "Epoch 37/300\n",
      "210/210 - 0s - loss: 0.5223 - mse: 0.5223 - 492ms/epoch - 2ms/step\n",
      "Epoch 38/300\n",
      "210/210 - 0s - loss: 0.5217 - mse: 0.5217 - 496ms/epoch - 2ms/step\n",
      "Epoch 39/300\n",
      "210/210 - 1s - loss: 0.5205 - mse: 0.5205 - 510ms/epoch - 2ms/step\n",
      "Epoch 40/300\n",
      "210/210 - 0s - loss: 0.5204 - mse: 0.5204 - 492ms/epoch - 2ms/step\n",
      "Epoch 41/300\n",
      "210/210 - 0s - loss: 0.5194 - mse: 0.5194 - 495ms/epoch - 2ms/step\n",
      "Epoch 42/300\n",
      "210/210 - 0s - loss: 0.5189 - mse: 0.5189 - 480ms/epoch - 2ms/step\n",
      "Epoch 43/300\n",
      "210/210 - 0s - loss: 0.5184 - mse: 0.5184 - 496ms/epoch - 2ms/step\n",
      "Epoch 44/300\n",
      "210/210 - 0s - loss: 0.5176 - mse: 0.5176 - 490ms/epoch - 2ms/step\n",
      "Epoch 45/300\n",
      "210/210 - 1s - loss: 0.5169 - mse: 0.5169 - 501ms/epoch - 2ms/step\n",
      "Epoch 46/300\n",
      "210/210 - 1s - loss: 0.5164 - mse: 0.5164 - 502ms/epoch - 2ms/step\n",
      "Epoch 47/300\n",
      "210/210 - 0s - loss: 0.5161 - mse: 0.5161 - 497ms/epoch - 2ms/step\n",
      "Epoch 48/300\n",
      "210/210 - 0s - loss: 0.5159 - mse: 0.5159 - 488ms/epoch - 2ms/step\n",
      "Epoch 49/300\n",
      "210/210 - 1s - loss: 0.5151 - mse: 0.5151 - 502ms/epoch - 2ms/step\n",
      "Epoch 50/300\n",
      "210/210 - 1s - loss: 0.5148 - mse: 0.5148 - 508ms/epoch - 2ms/step\n",
      "Epoch 51/300\n",
      "210/210 - 1s - loss: 0.5144 - mse: 0.5144 - 505ms/epoch - 2ms/step\n",
      "Epoch 52/300\n",
      "210/210 - 1s - loss: 0.5137 - mse: 0.5137 - 535ms/epoch - 3ms/step\n",
      "Epoch 53/300\n",
      "210/210 - 1s - loss: 0.5135 - mse: 0.5135 - 500ms/epoch - 2ms/step\n",
      "Epoch 54/300\n",
      "210/210 - 0s - loss: 0.5133 - mse: 0.5133 - 496ms/epoch - 2ms/step\n",
      "Epoch 55/300\n",
      "210/210 - 0s - loss: 0.5126 - mse: 0.5126 - 498ms/epoch - 2ms/step\n",
      "Epoch 56/300\n",
      "210/210 - 1s - loss: 0.5128 - mse: 0.5128 - 505ms/epoch - 2ms/step\n",
      "Epoch 57/300\n",
      "210/210 - 1s - loss: 0.5121 - mse: 0.5121 - 500ms/epoch - 2ms/step\n",
      "Epoch 58/300\n",
      "210/210 - 1s - loss: 0.5118 - mse: 0.5118 - 513ms/epoch - 2ms/step\n",
      "Epoch 59/300\n",
      "210/210 - 0s - loss: 0.5111 - mse: 0.5111 - 499ms/epoch - 2ms/step\n",
      "Epoch 60/300\n",
      "210/210 - 0s - loss: 0.5114 - mse: 0.5114 - 496ms/epoch - 2ms/step\n",
      "Epoch 61/300\n",
      "210/210 - 0s - loss: 0.5111 - mse: 0.5111 - 500ms/epoch - 2ms/step\n",
      "Epoch 62/300\n",
      "210/210 - 1s - loss: 0.5109 - mse: 0.5109 - 505ms/epoch - 2ms/step\n",
      "Epoch 63/300\n",
      "210/210 - 0s - loss: 0.5104 - mse: 0.5104 - 499ms/epoch - 2ms/step\n",
      "Epoch 64/300\n",
      "210/210 - 1s - loss: 0.5101 - mse: 0.5101 - 522ms/epoch - 2ms/step\n",
      "Epoch 65/300\n",
      "210/210 - 0s - loss: 0.5099 - mse: 0.5099 - 495ms/epoch - 2ms/step\n",
      "Epoch 66/300\n",
      "210/210 - 0s - loss: 0.5099 - mse: 0.5099 - 499ms/epoch - 2ms/step\n",
      "Epoch 67/300\n",
      "210/210 - 0s - loss: 0.5096 - mse: 0.5096 - 489ms/epoch - 2ms/step\n",
      "Epoch 68/300\n",
      "210/210 - 0s - loss: 0.5092 - mse: 0.5092 - 482ms/epoch - 2ms/step\n",
      "Epoch 69/300\n",
      "210/210 - 1s - loss: 0.5092 - mse: 0.5092 - 552ms/epoch - 3ms/step\n",
      "Epoch 70/300\n",
      "210/210 - 1s - loss: 0.5086 - mse: 0.5086 - 513ms/epoch - 2ms/step\n",
      "Epoch 71/300\n",
      "210/210 - 0s - loss: 0.5085 - mse: 0.5085 - 492ms/epoch - 2ms/step\n",
      "Epoch 72/300\n",
      "210/210 - 1s - loss: 0.5079 - mse: 0.5079 - 502ms/epoch - 2ms/step\n",
      "Epoch 73/300\n",
      "210/210 - 0s - loss: 0.5075 - mse: 0.5075 - 483ms/epoch - 2ms/step\n",
      "Epoch 74/300\n",
      "210/210 - 1s - loss: 0.5070 - mse: 0.5070 - 504ms/epoch - 2ms/step\n",
      "Epoch 75/300\n",
      "210/210 - 0s - loss: 0.5066 - mse: 0.5066 - 482ms/epoch - 2ms/step\n",
      "Epoch 76/300\n",
      "210/210 - 0s - loss: 0.5065 - mse: 0.5065 - 491ms/epoch - 2ms/step\n",
      "Epoch 77/300\n",
      "210/210 - 0s - loss: 0.5064 - mse: 0.5064 - 494ms/epoch - 2ms/step\n",
      "Epoch 78/300\n",
      "210/210 - 0s - loss: 0.5059 - mse: 0.5059 - 489ms/epoch - 2ms/step\n",
      "Epoch 79/300\n",
      "210/210 - 0s - loss: 0.5056 - mse: 0.5056 - 486ms/epoch - 2ms/step\n",
      "Epoch 80/300\n",
      "210/210 - 0s - loss: 0.5050 - mse: 0.5050 - 486ms/epoch - 2ms/step\n",
      "Epoch 81/300\n",
      "210/210 - 0s - loss: 0.5050 - mse: 0.5050 - 480ms/epoch - 2ms/step\n",
      "Epoch 82/300\n",
      "210/210 - 1s - loss: 0.5046 - mse: 0.5046 - 627ms/epoch - 3ms/step\n",
      "Epoch 83/300\n",
      "210/210 - 1s - loss: 0.5043 - mse: 0.5043 - 633ms/epoch - 3ms/step\n",
      "Epoch 84/300\n",
      "210/210 - 1s - loss: 0.5040 - mse: 0.5040 - 533ms/epoch - 3ms/step\n",
      "Epoch 85/300\n",
      "210/210 - 1s - loss: 0.5036 - mse: 0.5036 - 524ms/epoch - 2ms/step\n",
      "Epoch 86/300\n",
      "210/210 - 0s - loss: 0.5030 - mse: 0.5030 - 494ms/epoch - 2ms/step\n",
      "Epoch 87/300\n",
      "210/210 - 0s - loss: 0.5031 - mse: 0.5031 - 486ms/epoch - 2ms/step\n",
      "Epoch 88/300\n",
      "210/210 - 0s - loss: 0.5026 - mse: 0.5026 - 493ms/epoch - 2ms/step\n",
      "Epoch 89/300\n",
      "210/210 - 0s - loss: 0.5024 - mse: 0.5024 - 492ms/epoch - 2ms/step\n",
      "Epoch 90/300\n",
      "210/210 - 0s - loss: 0.5018 - mse: 0.5018 - 494ms/epoch - 2ms/step\n",
      "Epoch 91/300\n",
      "210/210 - 0s - loss: 0.5017 - mse: 0.5017 - 489ms/epoch - 2ms/step\n",
      "Epoch 92/300\n",
      "210/210 - 0s - loss: 0.5010 - mse: 0.5010 - 482ms/epoch - 2ms/step\n",
      "Epoch 93/300\n",
      "210/210 - 0s - loss: 0.5008 - mse: 0.5008 - 451ms/epoch - 2ms/step\n",
      "Epoch 94/300\n",
      "210/210 - 0s - loss: 0.5005 - mse: 0.5005 - 499ms/epoch - 2ms/step\n",
      "Epoch 95/300\n",
      "210/210 - 1s - loss: 0.5006 - mse: 0.5006 - 506ms/epoch - 2ms/step\n",
      "Epoch 96/300\n",
      "210/210 - 0s - loss: 0.5000 - mse: 0.5000 - 495ms/epoch - 2ms/step\n",
      "Epoch 97/300\n",
      "210/210 - 0s - loss: 0.4992 - mse: 0.4992 - 474ms/epoch - 2ms/step\n",
      "Epoch 98/300\n",
      "210/210 - 0s - loss: 0.4995 - mse: 0.4995 - 481ms/epoch - 2ms/step\n",
      "Epoch 99/300\n",
      "210/210 - 0s - loss: 0.4990 - mse: 0.4990 - 471ms/epoch - 2ms/step\n",
      "Epoch 100/300\n",
      "210/210 - 0s - loss: 0.4986 - mse: 0.4986 - 488ms/epoch - 2ms/step\n",
      "Epoch 101/300\n",
      "210/210 - 1s - loss: 0.4981 - mse: 0.4981 - 505ms/epoch - 2ms/step\n",
      "Epoch 102/300\n",
      "210/210 - 0s - loss: 0.4976 - mse: 0.4976 - 495ms/epoch - 2ms/step\n",
      "Epoch 103/300\n",
      "210/210 - 0s - loss: 0.4971 - mse: 0.4971 - 497ms/epoch - 2ms/step\n",
      "Epoch 104/300\n",
      "210/210 - 0s - loss: 0.4971 - mse: 0.4971 - 500ms/epoch - 2ms/step\n",
      "Epoch 105/300\n",
      "210/210 - 1s - loss: 0.4968 - mse: 0.4968 - 513ms/epoch - 2ms/step\n",
      "Epoch 106/300\n",
      "210/210 - 1s - loss: 0.4963 - mse: 0.4963 - 584ms/epoch - 3ms/step\n",
      "Epoch 107/300\n",
      "210/210 - 1s - loss: 0.4961 - mse: 0.4961 - 504ms/epoch - 2ms/step\n",
      "Epoch 108/300\n",
      "210/210 - 0s - loss: 0.4956 - mse: 0.4956 - 491ms/epoch - 2ms/step\n",
      "Epoch 109/300\n",
      "210/210 - 1s - loss: 0.4951 - mse: 0.4951 - 515ms/epoch - 2ms/step\n",
      "Epoch 110/300\n",
      "210/210 - 1s - loss: 0.4951 - mse: 0.4951 - 547ms/epoch - 3ms/step\n",
      "Epoch 111/300\n",
      "210/210 - 1s - loss: 0.4943 - mse: 0.4943 - 533ms/epoch - 3ms/step\n",
      "Epoch 112/300\n",
      "210/210 - 1s - loss: 0.4946 - mse: 0.4946 - 520ms/epoch - 2ms/step\n",
      "Epoch 113/300\n",
      "210/210 - 0s - loss: 0.4945 - mse: 0.4945 - 475ms/epoch - 2ms/step\n",
      "Epoch 114/300\n",
      "210/210 - 0s - loss: 0.4936 - mse: 0.4936 - 494ms/epoch - 2ms/step\n",
      "Epoch 115/300\n",
      "210/210 - 0s - loss: 0.4932 - mse: 0.4932 - 450ms/epoch - 2ms/step\n",
      "Epoch 116/300\n",
      "210/210 - 1s - loss: 0.4934 - mse: 0.4934 - 554ms/epoch - 3ms/step\n",
      "Epoch 117/300\n",
      "210/210 - 1s - loss: 0.4931 - mse: 0.4931 - 500ms/epoch - 2ms/step\n",
      "Epoch 118/300\n",
      "210/210 - 0s - loss: 0.4922 - mse: 0.4922 - 494ms/epoch - 2ms/step\n",
      "Epoch 119/300\n",
      "210/210 - 0s - loss: 0.4919 - mse: 0.4919 - 492ms/epoch - 2ms/step\n",
      "Epoch 120/300\n",
      "210/210 - 1s - loss: 0.4919 - mse: 0.4919 - 509ms/epoch - 2ms/step\n",
      "Epoch 121/300\n",
      "210/210 - 0s - loss: 0.4914 - mse: 0.4914 - 478ms/epoch - 2ms/step\n",
      "Epoch 122/300\n",
      "210/210 - 0s - loss: 0.4909 - mse: 0.4909 - 482ms/epoch - 2ms/step\n",
      "Epoch 123/300\n",
      "210/210 - 0s - loss: 0.4908 - mse: 0.4908 - 490ms/epoch - 2ms/step\n",
      "Epoch 124/300\n",
      "210/210 - 0s - loss: 0.4902 - mse: 0.4902 - 496ms/epoch - 2ms/step\n",
      "Epoch 125/300\n",
      "210/210 - 1s - loss: 0.4903 - mse: 0.4903 - 500ms/epoch - 2ms/step\n",
      "Epoch 126/300\n",
      "210/210 - 0s - loss: 0.4896 - mse: 0.4896 - 493ms/epoch - 2ms/step\n",
      "Epoch 127/300\n",
      "210/210 - 0s - loss: 0.4894 - mse: 0.4894 - 496ms/epoch - 2ms/step\n",
      "Epoch 128/300\n",
      "210/210 - 0s - loss: 0.4891 - mse: 0.4891 - 487ms/epoch - 2ms/step\n",
      "Epoch 129/300\n",
      "210/210 - 0s - loss: 0.4885 - mse: 0.4885 - 476ms/epoch - 2ms/step\n",
      "Epoch 130/300\n",
      "210/210 - 0s - loss: 0.4883 - mse: 0.4883 - 467ms/epoch - 2ms/step\n",
      "Epoch 131/300\n",
      "210/210 - 0s - loss: 0.4876 - mse: 0.4876 - 462ms/epoch - 2ms/step\n",
      "Epoch 132/300\n",
      "210/210 - 1s - loss: 0.4875 - mse: 0.4875 - 537ms/epoch - 3ms/step\n",
      "Epoch 133/300\n",
      "210/210 - 1s - loss: 0.4871 - mse: 0.4871 - 504ms/epoch - 2ms/step\n",
      "Epoch 134/300\n",
      "210/210 - 1s - loss: 0.4872 - mse: 0.4872 - 505ms/epoch - 2ms/step\n",
      "Epoch 135/300\n",
      "210/210 - 0s - loss: 0.4866 - mse: 0.4866 - 489ms/epoch - 2ms/step\n",
      "Epoch 136/300\n",
      "210/210 - 0s - loss: 0.4862 - mse: 0.4862 - 477ms/epoch - 2ms/step\n",
      "Epoch 137/300\n",
      "210/210 - 0s - loss: 0.4862 - mse: 0.4862 - 479ms/epoch - 2ms/step\n",
      "Epoch 138/300\n",
      "210/210 - 0s - loss: 0.4855 - mse: 0.4855 - 463ms/epoch - 2ms/step\n",
      "Epoch 139/300\n",
      "210/210 - 0s - loss: 0.4853 - mse: 0.4853 - 484ms/epoch - 2ms/step\n",
      "Epoch 140/300\n",
      "210/210 - 1s - loss: 0.4846 - mse: 0.4846 - 524ms/epoch - 2ms/step\n",
      "Epoch 141/300\n",
      "210/210 - 1s - loss: 0.4847 - mse: 0.4847 - 507ms/epoch - 2ms/step\n",
      "Epoch 142/300\n",
      "210/210 - 0s - loss: 0.4842 - mse: 0.4842 - 480ms/epoch - 2ms/step\n",
      "Epoch 143/300\n",
      "210/210 - 0s - loss: 0.4838 - mse: 0.4838 - 467ms/epoch - 2ms/step\n",
      "Epoch 144/300\n",
      "210/210 - 0s - loss: 0.4836 - mse: 0.4836 - 491ms/epoch - 2ms/step\n",
      "Epoch 145/300\n",
      "210/210 - 0s - loss: 0.4834 - mse: 0.4834 - 491ms/epoch - 2ms/step\n",
      "Epoch 146/300\n",
      "210/210 - 0s - loss: 0.4830 - mse: 0.4830 - 487ms/epoch - 2ms/step\n",
      "Epoch 147/300\n",
      "210/210 - 1s - loss: 0.4831 - mse: 0.4831 - 512ms/epoch - 2ms/step\n",
      "Epoch 148/300\n",
      "210/210 - 1s - loss: 0.4822 - mse: 0.4822 - 555ms/epoch - 3ms/step\n",
      "Epoch 149/300\n",
      "210/210 - 1s - loss: 0.4820 - mse: 0.4820 - 562ms/epoch - 3ms/step\n",
      "Epoch 150/300\n",
      "210/210 - 1s - loss: 0.4820 - mse: 0.4820 - 536ms/epoch - 3ms/step\n",
      "Epoch 151/300\n",
      "210/210 - 1s - loss: 0.4814 - mse: 0.4814 - 618ms/epoch - 3ms/step\n",
      "Epoch 152/300\n",
      "210/210 - 1s - loss: 0.4816 - mse: 0.4816 - 512ms/epoch - 2ms/step\n",
      "Epoch 153/300\n",
      "210/210 - 1s - loss: 0.4806 - mse: 0.4806 - 638ms/epoch - 3ms/step\n",
      "Epoch 154/300\n",
      "210/210 - 1s - loss: 0.4808 - mse: 0.4808 - 1s/epoch - 5ms/step\n",
      "Epoch 155/300\n",
      "210/210 - 1s - loss: 0.4803 - mse: 0.4803 - 616ms/epoch - 3ms/step\n",
      "Epoch 156/300\n",
      "210/210 - 1s - loss: 0.4802 - mse: 0.4802 - 530ms/epoch - 3ms/step\n",
      "Epoch 157/300\n",
      "210/210 - 1s - loss: 0.4801 - mse: 0.4801 - 569ms/epoch - 3ms/step\n",
      "Epoch 158/300\n",
      "210/210 - 1s - loss: 0.4793 - mse: 0.4793 - 544ms/epoch - 3ms/step\n",
      "Epoch 159/300\n",
      "210/210 - 0s - loss: 0.4796 - mse: 0.4796 - 485ms/epoch - 2ms/step\n",
      "Epoch 160/300\n",
      "210/210 - 0s - loss: 0.4794 - mse: 0.4794 - 477ms/epoch - 2ms/step\n",
      "Epoch 161/300\n",
      "210/210 - 1s - loss: 0.4789 - mse: 0.4789 - 753ms/epoch - 4ms/step\n",
      "Epoch 162/300\n",
      "210/210 - 1s - loss: 0.4786 - mse: 0.4786 - 535ms/epoch - 3ms/step\n",
      "Epoch 163/300\n",
      "210/210 - 1s - loss: 0.4788 - mse: 0.4788 - 506ms/epoch - 2ms/step\n",
      "Epoch 164/300\n",
      "210/210 - 0s - loss: 0.4787 - mse: 0.4787 - 481ms/epoch - 2ms/step\n",
      "Epoch 165/300\n",
      "210/210 - 1s - loss: 0.4781 - mse: 0.4781 - 525ms/epoch - 3ms/step\n",
      "Epoch 166/300\n",
      "210/210 - 1s - loss: 0.4777 - mse: 0.4777 - 501ms/epoch - 2ms/step\n",
      "Epoch 167/300\n",
      "210/210 - 1s - loss: 0.4774 - mse: 0.4774 - 508ms/epoch - 2ms/step\n",
      "Epoch 168/300\n",
      "210/210 - 1s - loss: 0.4776 - mse: 0.4776 - 502ms/epoch - 2ms/step\n",
      "Epoch 169/300\n",
      "210/210 - 1s - loss: 0.4773 - mse: 0.4773 - 545ms/epoch - 3ms/step\n",
      "Epoch 170/300\n",
      "210/210 - 0s - loss: 0.4770 - mse: 0.4770 - 499ms/epoch - 2ms/step\n",
      "Epoch 171/300\n",
      "210/210 - 0s - loss: 0.4772 - mse: 0.4772 - 493ms/epoch - 2ms/step\n",
      "Epoch 172/300\n",
      "210/210 - 0s - loss: 0.4767 - mse: 0.4767 - 492ms/epoch - 2ms/step\n",
      "Epoch 173/300\n",
      "210/210 - 0s - loss: 0.4765 - mse: 0.4765 - 481ms/epoch - 2ms/step\n",
      "Epoch 174/300\n",
      "210/210 - 0s - loss: 0.4765 - mse: 0.4765 - 467ms/epoch - 2ms/step\n",
      "Epoch 175/300\n",
      "210/210 - 0s - loss: 0.4762 - mse: 0.4762 - 496ms/epoch - 2ms/step\n",
      "Epoch 176/300\n",
      "210/210 - 0s - loss: 0.4758 - mse: 0.4758 - 487ms/epoch - 2ms/step\n",
      "Epoch 177/300\n",
      "210/210 - 1s - loss: 0.4757 - mse: 0.4757 - 519ms/epoch - 2ms/step\n",
      "Epoch 178/300\n",
      "210/210 - 0s - loss: 0.4757 - mse: 0.4757 - 488ms/epoch - 2ms/step\n",
      "Epoch 179/300\n",
      "210/210 - 0s - loss: 0.4750 - mse: 0.4750 - 468ms/epoch - 2ms/step\n",
      "Epoch 180/300\n",
      "210/210 - 0s - loss: 0.4755 - mse: 0.4755 - 472ms/epoch - 2ms/step\n",
      "Epoch 181/300\n",
      "210/210 - 0s - loss: 0.4750 - mse: 0.4750 - 491ms/epoch - 2ms/step\n",
      "Epoch 182/300\n",
      "210/210 - 0s - loss: 0.4748 - mse: 0.4748 - 499ms/epoch - 2ms/step\n",
      "Epoch 183/300\n",
      "210/210 - 0s - loss: 0.4749 - mse: 0.4749 - 483ms/epoch - 2ms/step\n",
      "Epoch 184/300\n",
      "210/210 - 0s - loss: 0.4745 - mse: 0.4745 - 485ms/epoch - 2ms/step\n",
      "Epoch 185/300\n",
      "210/210 - 0s - loss: 0.4741 - mse: 0.4741 - 488ms/epoch - 2ms/step\n",
      "Epoch 186/300\n",
      "210/210 - 0s - loss: 0.4738 - mse: 0.4738 - 486ms/epoch - 2ms/step\n",
      "Epoch 187/300\n",
      "210/210 - 0s - loss: 0.4744 - mse: 0.4744 - 468ms/epoch - 2ms/step\n",
      "Epoch 188/300\n",
      "210/210 - 0s - loss: 0.4742 - mse: 0.4742 - 468ms/epoch - 2ms/step\n",
      "Epoch 189/300\n",
      "210/210 - 0s - loss: 0.4736 - mse: 0.4736 - 467ms/epoch - 2ms/step\n",
      "Epoch 190/300\n",
      "210/210 - 0s - loss: 0.4734 - mse: 0.4734 - 453ms/epoch - 2ms/step\n",
      "Epoch 191/300\n",
      "210/210 - 0s - loss: 0.4732 - mse: 0.4732 - 460ms/epoch - 2ms/step\n",
      "Epoch 192/300\n",
      "210/210 - 0s - loss: 0.4729 - mse: 0.4729 - 478ms/epoch - 2ms/step\n",
      "Epoch 193/300\n",
      "210/210 - 1s - loss: 0.4729 - mse: 0.4729 - 505ms/epoch - 2ms/step\n",
      "Epoch 194/300\n",
      "210/210 - 0s - loss: 0.4726 - mse: 0.4726 - 481ms/epoch - 2ms/step\n",
      "Epoch 195/300\n",
      "210/210 - 0s - loss: 0.4726 - mse: 0.4726 - 483ms/epoch - 2ms/step\n",
      "Epoch 196/300\n",
      "210/210 - 0s - loss: 0.4726 - mse: 0.4726 - 487ms/epoch - 2ms/step\n",
      "Epoch 197/300\n",
      "210/210 - 0s - loss: 0.4722 - mse: 0.4722 - 478ms/epoch - 2ms/step\n",
      "Epoch 198/300\n",
      "210/210 - 0s - loss: 0.4723 - mse: 0.4723 - 475ms/epoch - 2ms/step\n",
      "Epoch 199/300\n",
      "210/210 - 0s - loss: 0.4718 - mse: 0.4718 - 483ms/epoch - 2ms/step\n",
      "Epoch 200/300\n",
      "210/210 - 0s - loss: 0.4722 - mse: 0.4722 - 479ms/epoch - 2ms/step\n",
      "Epoch 201/300\n",
      "210/210 - 0s - loss: 0.4721 - mse: 0.4721 - 475ms/epoch - 2ms/step\n",
      "Epoch 202/300\n",
      "210/210 - 0s - loss: 0.4712 - mse: 0.4712 - 486ms/epoch - 2ms/step\n",
      "Epoch 203/300\n",
      "210/210 - 0s - loss: 0.4712 - mse: 0.4712 - 464ms/epoch - 2ms/step\n",
      "Epoch 204/300\n",
      "210/210 - 0s - loss: 0.4708 - mse: 0.4708 - 474ms/epoch - 2ms/step\n",
      "Epoch 205/300\n",
      "210/210 - 0s - loss: 0.4716 - mse: 0.4716 - 497ms/epoch - 2ms/step\n",
      "Epoch 206/300\n",
      "210/210 - 1s - loss: 0.4707 - mse: 0.4707 - 504ms/epoch - 2ms/step\n",
      "Epoch 207/300\n",
      "210/210 - 0s - loss: 0.4704 - mse: 0.4704 - 468ms/epoch - 2ms/step\n",
      "Epoch 208/300\n",
      "210/210 - 0s - loss: 0.4704 - mse: 0.4704 - 449ms/epoch - 2ms/step\n",
      "Epoch 209/300\n",
      "210/210 - 1s - loss: 0.4702 - mse: 0.4702 - 525ms/epoch - 2ms/step\n",
      "Epoch 210/300\n",
      "210/210 - 0s - loss: 0.4701 - mse: 0.4701 - 494ms/epoch - 2ms/step\n",
      "Epoch 211/300\n",
      "210/210 - 0s - loss: 0.4696 - mse: 0.4696 - 483ms/epoch - 2ms/step\n",
      "Epoch 212/300\n",
      "210/210 - 1s - loss: 0.4699 - mse: 0.4699 - 500ms/epoch - 2ms/step\n",
      "Epoch 213/300\n",
      "210/210 - 1s - loss: 0.4700 - mse: 0.4700 - 546ms/epoch - 3ms/step\n",
      "Epoch 214/300\n",
      "210/210 - 0s - loss: 0.4694 - mse: 0.4694 - 474ms/epoch - 2ms/step\n",
      "Epoch 215/300\n",
      "210/210 - 0s - loss: 0.4694 - mse: 0.4694 - 471ms/epoch - 2ms/step\n",
      "Epoch 216/300\n",
      "210/210 - 1s - loss: 0.4687 - mse: 0.4687 - 501ms/epoch - 2ms/step\n",
      "Epoch 217/300\n",
      "210/210 - 0s - loss: 0.4688 - mse: 0.4688 - 489ms/epoch - 2ms/step\n",
      "Epoch 218/300\n",
      "210/210 - 1s - loss: 0.4684 - mse: 0.4684 - 508ms/epoch - 2ms/step\n",
      "Epoch 219/300\n",
      "210/210 - 0s - loss: 0.4684 - mse: 0.4684 - 485ms/epoch - 2ms/step\n",
      "Epoch 220/300\n",
      "210/210 - 0s - loss: 0.4680 - mse: 0.4680 - 484ms/epoch - 2ms/step\n",
      "Epoch 221/300\n",
      "210/210 - 1s - loss: 0.4682 - mse: 0.4682 - 514ms/epoch - 2ms/step\n",
      "Epoch 222/300\n",
      "210/210 - 0s - loss: 0.4676 - mse: 0.4676 - 492ms/epoch - 2ms/step\n",
      "Epoch 223/300\n",
      "210/210 - 0s - loss: 0.4678 - mse: 0.4678 - 485ms/epoch - 2ms/step\n",
      "Epoch 224/300\n",
      "210/210 - 1s - loss: 0.4674 - mse: 0.4674 - 500ms/epoch - 2ms/step\n",
      "Epoch 225/300\n",
      "210/210 - 1s - loss: 0.4673 - mse: 0.4673 - 502ms/epoch - 2ms/step\n",
      "Epoch 226/300\n",
      "210/210 - 0s - loss: 0.4671 - mse: 0.4671 - 487ms/epoch - 2ms/step\n",
      "Epoch 227/300\n",
      "210/210 - 0s - loss: 0.4670 - mse: 0.4670 - 477ms/epoch - 2ms/step\n",
      "Epoch 228/300\n",
      "210/210 - 0s - loss: 0.4670 - mse: 0.4670 - 493ms/epoch - 2ms/step\n",
      "Epoch 229/300\n",
      "210/210 - 0s - loss: 0.4668 - mse: 0.4668 - 480ms/epoch - 2ms/step\n",
      "Epoch 230/300\n",
      "210/210 - 0s - loss: 0.4664 - mse: 0.4664 - 478ms/epoch - 2ms/step\n",
      "Epoch 231/300\n",
      "210/210 - 0s - loss: 0.4659 - mse: 0.4659 - 493ms/epoch - 2ms/step\n",
      "Epoch 232/300\n",
      "210/210 - 0s - loss: 0.4660 - mse: 0.4660 - 469ms/epoch - 2ms/step\n",
      "Epoch 233/300\n",
      "210/210 - 0s - loss: 0.4661 - mse: 0.4661 - 489ms/epoch - 2ms/step\n",
      "Epoch 234/300\n",
      "210/210 - 0s - loss: 0.4658 - mse: 0.4658 - 479ms/epoch - 2ms/step\n",
      "Epoch 235/300\n",
      "210/210 - 0s - loss: 0.4654 - mse: 0.4654 - 477ms/epoch - 2ms/step\n",
      "Epoch 236/300\n",
      "210/210 - 0s - loss: 0.4654 - mse: 0.4654 - 483ms/epoch - 2ms/step\n",
      "Epoch 237/300\n",
      "210/210 - 0s - loss: 0.4650 - mse: 0.4650 - 498ms/epoch - 2ms/step\n",
      "Epoch 238/300\n",
      "210/210 - 0s - loss: 0.4649 - mse: 0.4649 - 489ms/epoch - 2ms/step\n",
      "Epoch 239/300\n",
      "210/210 - 0s - loss: 0.4649 - mse: 0.4649 - 494ms/epoch - 2ms/step\n",
      "Epoch 240/300\n",
      "210/210 - 0s - loss: 0.4647 - mse: 0.4647 - 487ms/epoch - 2ms/step\n",
      "Epoch 241/300\n",
      "210/210 - 0s - loss: 0.4643 - mse: 0.4643 - 482ms/epoch - 2ms/step\n",
      "Epoch 242/300\n",
      "210/210 - 0s - loss: 0.4645 - mse: 0.4645 - 481ms/epoch - 2ms/step\n",
      "Epoch 243/300\n",
      "210/210 - 0s - loss: 0.4637 - mse: 0.4637 - 485ms/epoch - 2ms/step\n",
      "Epoch 244/300\n",
      "210/210 - 0s - loss: 0.4636 - mse: 0.4636 - 491ms/epoch - 2ms/step\n",
      "Epoch 245/300\n",
      "210/210 - 0s - loss: 0.4636 - mse: 0.4636 - 473ms/epoch - 2ms/step\n",
      "Epoch 246/300\n",
      "210/210 - 0s - loss: 0.4633 - mse: 0.4633 - 479ms/epoch - 2ms/step\n",
      "Epoch 247/300\n",
      "210/210 - 0s - loss: 0.4633 - mse: 0.4633 - 490ms/epoch - 2ms/step\n",
      "Epoch 248/300\n",
      "210/210 - 0s - loss: 0.4629 - mse: 0.4629 - 486ms/epoch - 2ms/step\n",
      "Epoch 249/300\n",
      "210/210 - 0s - loss: 0.4629 - mse: 0.4629 - 486ms/epoch - 2ms/step\n",
      "Epoch 250/300\n",
      "210/210 - 1s - loss: 0.4622 - mse: 0.4622 - 511ms/epoch - 2ms/step\n",
      "Epoch 251/300\n",
      "210/210 - 0s - loss: 0.4621 - mse: 0.4621 - 494ms/epoch - 2ms/step\n",
      "Epoch 252/300\n",
      "210/210 - 0s - loss: 0.4622 - mse: 0.4622 - 481ms/epoch - 2ms/step\n",
      "Epoch 253/300\n",
      "210/210 - 0s - loss: 0.4623 - mse: 0.4623 - 493ms/epoch - 2ms/step\n",
      "Epoch 254/300\n",
      "210/210 - 0s - loss: 0.4616 - mse: 0.4616 - 491ms/epoch - 2ms/step\n",
      "Epoch 255/300\n",
      "210/210 - 0s - loss: 0.4613 - mse: 0.4613 - 492ms/epoch - 2ms/step\n",
      "Epoch 256/300\n",
      "210/210 - 1s - loss: 0.4615 - mse: 0.4615 - 503ms/epoch - 2ms/step\n",
      "Epoch 257/300\n",
      "210/210 - 0s - loss: 0.4611 - mse: 0.4611 - 485ms/epoch - 2ms/step\n",
      "Epoch 258/300\n",
      "210/210 - 0s - loss: 0.4610 - mse: 0.4610 - 483ms/epoch - 2ms/step\n",
      "Epoch 259/300\n",
      "210/210 - 1s - loss: 0.4606 - mse: 0.4606 - 516ms/epoch - 2ms/step\n",
      "Epoch 260/300\n",
      "210/210 - 0s - loss: 0.4602 - mse: 0.4602 - 477ms/epoch - 2ms/step\n",
      "Epoch 261/300\n",
      "210/210 - 1s - loss: 0.4598 - mse: 0.4598 - 504ms/epoch - 2ms/step\n",
      "Epoch 262/300\n",
      "210/210 - 0s - loss: 0.4599 - mse: 0.4599 - 498ms/epoch - 2ms/step\n",
      "Epoch 263/300\n",
      "210/210 - 0s - loss: 0.4599 - mse: 0.4599 - 483ms/epoch - 2ms/step\n",
      "Epoch 264/300\n",
      "210/210 - 0s - loss: 0.4593 - mse: 0.4593 - 482ms/epoch - 2ms/step\n",
      "Epoch 265/300\n",
      "210/210 - 0s - loss: 0.4590 - mse: 0.4590 - 497ms/epoch - 2ms/step\n",
      "Epoch 266/300\n",
      "210/210 - 0s - loss: 0.4591 - mse: 0.4591 - 487ms/epoch - 2ms/step\n",
      "Epoch 267/300\n",
      "210/210 - 0s - loss: 0.4584 - mse: 0.4584 - 485ms/epoch - 2ms/step\n",
      "Epoch 268/300\n",
      "210/210 - 0s - loss: 0.4585 - mse: 0.4585 - 482ms/epoch - 2ms/step\n",
      "Epoch 269/300\n",
      "210/210 - 0s - loss: 0.4581 - mse: 0.4581 - 500ms/epoch - 2ms/step\n",
      "Epoch 270/300\n",
      "210/210 - 0s - loss: 0.4582 - mse: 0.4582 - 483ms/epoch - 2ms/step\n",
      "Epoch 271/300\n",
      "210/210 - 1s - loss: 0.4577 - mse: 0.4577 - 504ms/epoch - 2ms/step\n",
      "Epoch 272/300\n",
      "210/210 - 0s - loss: 0.4566 - mse: 0.4566 - 492ms/epoch - 2ms/step\n",
      "Epoch 273/300\n",
      "210/210 - 1s - loss: 0.4575 - mse: 0.4575 - 554ms/epoch - 3ms/step\n",
      "Epoch 274/300\n",
      "210/210 - 0s - loss: 0.4568 - mse: 0.4568 - 495ms/epoch - 2ms/step\n",
      "Epoch 275/300\n",
      "210/210 - 1s - loss: 0.4570 - mse: 0.4570 - 501ms/epoch - 2ms/step\n",
      "Epoch 276/300\n",
      "210/210 - 0s - loss: 0.4567 - mse: 0.4567 - 489ms/epoch - 2ms/step\n",
      "Epoch 277/300\n",
      "210/210 - 0s - loss: 0.4564 - mse: 0.4564 - 492ms/epoch - 2ms/step\n",
      "Epoch 278/300\n",
      "210/210 - 0s - loss: 0.4558 - mse: 0.4558 - 481ms/epoch - 2ms/step\n",
      "Epoch 279/300\n",
      "210/210 - 0s - loss: 0.4561 - mse: 0.4561 - 487ms/epoch - 2ms/step\n",
      "Epoch 280/300\n",
      "210/210 - 0s - loss: 0.4557 - mse: 0.4557 - 489ms/epoch - 2ms/step\n",
      "Epoch 281/300\n",
      "210/210 - 1s - loss: 0.4551 - mse: 0.4551 - 507ms/epoch - 2ms/step\n",
      "Epoch 282/300\n",
      "210/210 - 0s - loss: 0.4552 - mse: 0.4552 - 472ms/epoch - 2ms/step\n",
      "Epoch 283/300\n",
      "210/210 - 0s - loss: 0.4548 - mse: 0.4548 - 487ms/epoch - 2ms/step\n",
      "Epoch 284/300\n",
      "210/210 - 0s - loss: 0.4550 - mse: 0.4550 - 473ms/epoch - 2ms/step\n",
      "Epoch 285/300\n",
      "210/210 - 0s - loss: 0.4553 - mse: 0.4553 - 470ms/epoch - 2ms/step\n",
      "Epoch 286/300\n",
      "210/210 - 0s - loss: 0.4541 - mse: 0.4541 - 485ms/epoch - 2ms/step\n",
      "Epoch 287/300\n",
      "210/210 - 0s - loss: 0.4542 - mse: 0.4542 - 493ms/epoch - 2ms/step\n",
      "Epoch 288/300\n",
      "210/210 - 1s - loss: 0.4539 - mse: 0.4539 - 524ms/epoch - 2ms/step\n",
      "Epoch 289/300\n",
      "210/210 - 1s - loss: 0.4537 - mse: 0.4537 - 548ms/epoch - 3ms/step\n",
      "Epoch 290/300\n",
      "210/210 - 1s - loss: 0.4535 - mse: 0.4535 - 534ms/epoch - 3ms/step\n",
      "Epoch 291/300\n",
      "210/210 - 1s - loss: 0.4533 - mse: 0.4533 - 532ms/epoch - 3ms/step\n",
      "Epoch 292/300\n",
      "210/210 - 1s - loss: 0.4532 - mse: 0.4532 - 508ms/epoch - 2ms/step\n",
      "Epoch 293/300\n",
      "210/210 - 0s - loss: 0.4529 - mse: 0.4529 - 476ms/epoch - 2ms/step\n",
      "Epoch 294/300\n",
      "210/210 - 1s - loss: 0.4522 - mse: 0.4522 - 504ms/epoch - 2ms/step\n",
      "Epoch 295/300\n",
      "210/210 - 0s - loss: 0.4523 - mse: 0.4523 - 486ms/epoch - 2ms/step\n",
      "Epoch 296/300\n",
      "210/210 - 0s - loss: 0.4528 - mse: 0.4528 - 479ms/epoch - 2ms/step\n",
      "Epoch 297/300\n",
      "210/210 - 0s - loss: 0.4520 - mse: 0.4520 - 489ms/epoch - 2ms/step\n",
      "Epoch 298/300\n",
      "210/210 - 0s - loss: 0.4519 - mse: 0.4519 - 490ms/epoch - 2ms/step\n",
      "Epoch 299/300\n",
      "210/210 - 0s - loss: 0.4517 - mse: 0.4517 - 494ms/epoch - 2ms/step\n",
      "Epoch 300/300\n",
      "210/210 - 0s - loss: 0.4513 - mse: 0.4513 - 498ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19daeee8640>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train ,epochs=300, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 2ms/step - loss: 2.0997 - mse: 2.0997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.099684238433838, 2.099684238433838]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score : -0.20122443902116371\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"r2 score :\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_in = std2.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure((15,9))\n",
    "plt.plot(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"n_estimators\" : [10,20,30,50,70,100,120,150,200,300],\n",
    "    \"learning_rate\" : [0.001,0.05,0.02,0.01,0.5,0.2,0.1,1],\n",
    "    \"max_depth\" : [1,2,3,4,5,6,7]\n",
    "}\n",
    "grid = GridSearchCV(xgb, param_grid=param, cv=kfold, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = iris.data\n",
    "target = iris.target\n",
    "standardizer = StandardScaler() # 표준화 객체 생성\n",
    "knn = KNeighborsClassifier(n_neighbors=5, n_jobs=-1) # KNN 분류기 객체 생성\n",
    "pipe = Pipeline([(\"standardizer\", standardizer), (\"knn\", knn)]) # 파이프라인 생성\n",
    "# 탐색 영역의 후보를 만듭니다.\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "# 그리드 서치 객체 생성\n",
    "classifier = GridSearchCV( pipe, search_space, cv=5, verbose=0).fit(features, target)\n",
    "# 최선의 이웃 개수 (k)\n",
    "classifier.best_estimator_.get_params()[\"knn__n_neighbors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 딕셔너리 형태로 저장    {\"param\":[후보1, 후보2, ......]}\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "k_values = np.array([1,3,5,7,9,11,13,15,17,19,21])\n",
    "param_grid = dict(n_neighbors = k_values)\n",
    "model = KNeighborsRegressor()\n",
    "kfold = KFold(n_splits=10, random_state=3, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best Score :\", grid_result.best_score_)\n",
    "print(\"Best Parameters :\", grid_result.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration은 1 epoch를 시행할 때 필요한 미니배치 갯수를 의미합니다. 다른 말로는 1epoch을 마치는데 필요한 파라미터 업데이트 횟수\n",
    "\n",
    "만약 10,000개의 데이터셋을 학습시킨다고 치자. (여기서 학습은 순방향 역방향 둘 다 포함)\n",
    "\n",
    "메모리 한계 및 성능을 고려하여 나눠서 학습을 시킬 겁니다. \n",
    "\n",
    "이 때, 한 턴에 1,000개씩 10번 , 5턴을 학습시킨다고 하면, batch_size = 1,000 / iteration = 10 /epoch = 5입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.logspace(-4,2,7)   # lasso, ridge 해당\n",
    "learning_rate = np.logspace(-4,2,7)   # adaboost, gradientboost, xgboost 해당\n",
    "eta = np.logspace(-4,2,7)   # xgboost 해당\n",
    "max_iteration = [1,3,5,10,20,50,100,150,200]   # lasso, ridge 해당\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']   # ridge 해당, 계산에 사용할 알고리즘\n",
    "n_estimators = [1,3,5,10,15,20]   # randomforesteregressor(사용할 tree의 개수), gradientboost, adaboost, xgboost 해당\n",
    "max_depth = [2,3,5,7,10,12]  # randomforesteregressor(tree의 깊이), adaboost(boosting이 끝났을 때 estimator의 최대수), gradientboost, xgboost 해당\n",
    "criterion_rf = [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]  # randomforesteregressor 해당\n",
    "criterion_gb = [\"squared_error\", \"friedman_mse\"]  # gradientboost 해당\n",
    "loss_ada = [\"linear\", \"square\", \"exponential\"]    # adaboost 해당\n",
    "loss_gb = [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"]  # gradientboost 해당\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = [\"Lasso\"]\n",
    "model_ridge = [\"Ridge\"]\n",
    "model_rf = [\"RandomForestRegressor\"]\n",
    "model_ada = [\"AdaBoostRegressor\"] \n",
    "model_grad [\"GradientBoostingRegressor\"]\n",
    "model_xgb = [\"XGBRegressor\"]\n",
    "\n",
    "params_lasso = {\"alpha\" : alpha, \n",
    "                \"max_iteration\" : max_iteration}\n",
    "\n",
    "params_ridge = {\"alpha\" : alpha, \n",
    "                \"max_iteration\" : max_iteration, \n",
    "                \"solver\" : solver}\n",
    "\n",
    "params_rf = {\"n_estimators\" : n_estimators, \n",
    "                \"max_depth\" : max_depth, \n",
    "                \"criterion\" : criterion_rf}\n",
    "\n",
    "params_ensem = {\"learning_rate\" : learning_rate, \n",
    "                \"n_estimators\" : n_estimators, \n",
    "                \"max_depth\" : max_depth, \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"alpha\":alpha_learningRate,\n",
    "\"max_iter\" : []}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[5600. 5600. 5600. ... 5664. 5592. 5242.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m scaler\u001b[39m.\u001b[39mfit(feature)\n\u001b[0;32m      4\u001b[0m feature \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(feature)\n\u001b[1;32m----> 5\u001b[0m scaler\u001b[39m.\u001b[39;49mfit(target)\n\u001b[0;32m      6\u001b[0m target \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(target)\n\u001b[0;32m      8\u001b[0m \u001b[39m# 데이터셋 생성\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jhahn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32mc:\\Users\\jhahn\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    458\u001b[0m     X,\n\u001b[0;32m    459\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    460\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    461\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jhahn\\anaconda3\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\jhahn\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 879\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    880\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    881\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    882\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    884\u001b[0m         )\n\u001b[0;32m    886\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[5600. 5600. 5600. ... 5664. 5592. 5242.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# 데이터 스케일링\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(feature)\n",
    "feature = scaler.transform(feature)\n",
    "scaler.fit(target)\n",
    "target = scaler.transform(target)\n",
    "\n",
    "# 데이터셋 생성\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 데이터셋 생성\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(feature, look_back)\n",
    "testX, testY = create_dataset(target, look_back)\n",
    "\n",
    "# 데이터셋 형태 변환\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "\n",
    "# 예측\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# 데이터 스케일링 복원\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "# 모델 평가\n",
    "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, np.sqrt(trainScore)))\n",
    "testScore = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, np.sqrt(testScore)))\n",
    "\n",
    "# 예측 결과 시각화\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(testY[0], label='actual')\n",
    "plt.plot(testPredict, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 예측 결과 저장\n",
    "predic_df = pd.DataFrame(testPredict)\n",
    "\n",
    "# 예측 결과 저장\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de11d0c16539acdfeb0e501d4eda7b58b0438a2781c2c1df7ab38defdddf0dd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
